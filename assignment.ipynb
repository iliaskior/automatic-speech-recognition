{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yerWQD2Tzokl"
   },
   "source": [
    "## Import Modules and Prerequisites\n",
    "---\n",
    "Please use this section to import any necessary modules that will be required later in this notebook like the example given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:02:19.275150Z",
     "start_time": "2019-08-30T08:02:09.413650Z"
    },
    "id": "GCx876Ilzokm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# add any needed libraries\n",
    "from pathlib import Path\n",
    "from audioblock import *\n",
    "from model import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow.keras as keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "il8e-reUP7S_"
   },
   "source": [
    "## Automatic Speech Recognition\n",
    "---\n",
    "#### Note: There is no expectation of coding a highly sophisticated solution in this current small time period. Each question can be answered either with a short code example along with a possible written explaination of a more elaborate approach or with not highly tuned models, due to lack of available resources and time.\n",
    "\n",
    "A common task in Acoustics is to predict the speaker from corresponding audio signals (speaker identification). In the provided corpus (see the project description), you can find transcripts under various speech settings and speaking conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rNAWFkpJNOJ"
   },
   "source": [
    "### 1. Train a classifier on the Solo Speech condition dataset that will reach an acceptable accuracy score.\n",
    "---\n",
    "Feel free to follow any design choices you feel fit the problem best. Briefly describe your approach in markdown cells, along with any necessary comments on your choices. Explain your choices with the appropriate evaluation plots - analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nRuD2Jc2Ie41"
   },
   "outputs": [],
   "source": [
    "#Path initialization\n",
    "ROOT_PATH = Path.cwd()\n",
    "ROOT_DATASET_PATH = ROOT_PATH.joinpath('dataset')\n",
    "SOLO_DATASET_PATH = ROOT_DATASET_PATH.joinpath('data').joinpath('solo')\n",
    "TRAIN_FEATURES_EXPORT_PATH = ROOT_DATASET_PATH.joinpath('train_ftrs.pickle')\n",
    "OUTPUT_PATH = ROOT_PATH.joinpath('output')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list which contains all the audio files' paths in solo dataset\n",
    "audiofiles = list((SOLO_DATASET_PATH).glob('**/*.wav'))\n",
    "\n",
    "# Extract audio features for SOLO dataset\n",
    "create_features_dataset(filepaths=audiofiles, exportpath=TRAIN_FEATURES_EXPORT_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validatio and test sets for experimentation purposes\n",
    "def prepare_dataset(X, y, test_size=0.2, validation_size=0.2):\n",
    "    \"\"\"Creates train, validation and test sets.\"\"\"\n",
    "\n",
    "    # create train, validation, test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "\n",
    "    return X_train, y_train, X_validation, y_validation, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "#Load the extracted feature set for the SOLO dataset\n",
    "X, y = load_data(data_path = TRAIN_FEATURES_EXPORT_PATH)\n",
    "\n",
    "#Label encoding\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "#Split the dataset in train, val, test sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = prepare_dataset(X, y_enc)\n",
    "\n",
    "#Calculate the class weights (not totally necessary, the dataset is balanced in general)\n",
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(y_train),\n",
    "                                        y = y_train                                                   \n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# Create the deep neural network\n",
    "input_shape = (X_train.shape[1], X_train.shape[2]) # timesteps=16, features=39\n",
    "n_classes = len(list(le.classes_))\n",
    "model = build_model(input_shape, n_classes)\n",
    "\n",
    "# Train model using earling stopping as we have a validation set\n",
    "callback = EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_data=(X_val, y_val), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    epochs=MAX_EPOCHS, \n",
    "    class_weight=class_weights,\n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n",
    "# plot accuracy/error for training and validation\n",
    "plot_history(history, fullpath=OUTPUT_PATH.joinpath('train_history.jpg'))\n",
    "\n",
    "# evaluate model on test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "#Make predictions\n",
    "y_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "#Store results\n",
    "y_pred = le.inverse_transform(y_pred)\n",
    "y_test = le.inverse_transform(y_test)\n",
    "results = {\n",
    "    'label': y_test,\n",
    "    'prediction': y_pred,\n",
    "    'probabilities': y_prob.tolist()\n",
    "}\n",
    "\n",
    "# save results\n",
    "filename = OUTPUT_PATH.joinpath('experimentation_results.pickle')\n",
    "filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "plot_confusion_matrix(results['label'], results['prediction'], norm=False, fullpath=OUTPUT_PATH.joinpath('cm.jpg'))\n",
    "plot_confusion_matrix(results['label'], results['prediction'], norm=True, fullpath=OUTPUT_PATH.joinpath('normalized_cm.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97X2QamRrxw8"
   },
   "source": [
    "### 2. Assuming that you needed to apply the learned rules / models on the Fast Speech condition dataset, without having that (test) dataset beforehand, what you would do?\n",
    "---\n",
    "The goal is to approach the classification accuracy obtained on the train dataset to the test dataset, without using the latter for training. Describe any challenges (if they exist) and code your solution below following the same guidelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JqQXHnvO3_v"
   },
   "source": [
    "### 3. Another important task is to perform gender classification on the same datasets, but there are no available labels. You can use the entirety of data you have at your disposal. Describe possible approaches to this problem and code the most robust solution of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdSXQbB6IcyL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-9uwDOUzolE"
   },
   "source": [
    "## Thank you in advance. Good luck!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": [
    {
     "file_id": "1zLg8KDovmYmXsc3HcpVRNyU-XouJY4C9",
     "timestamp": 1630683886599
    },
    {
     "file_id": "0B_k471A7UcJSUS1ZWTNsWWV4T21CanBvME9iTUlXaUQtQlQw",
     "timestamp": 1554849290453
    }
   ]
  },
  "kernelspec": {
   "display_name": "brain_tumor_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "047cfb83cf53d8759eb3dcee9607eb42d46e6cd73ff22b9db25630cabfb0d3db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
